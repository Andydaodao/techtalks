{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Gadfly, RDatasets\n",
    "import ForwardDiff: gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f(x) = sum(x)*log(abs(sum(x)))\n",
    "f([2,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gradient(f, [2,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function GradientDescent(L, x0; rate=.1, N=100, eps=.001)\n",
    "    for i = 1:N \n",
    "        ∇L = gradient(L, x0)\n",
    "        if norm(∇L) < eps\n",
    "            break\n",
    "        end\n",
    "        x0 -= rate * ∇L\n",
    "    end\n",
    "    x0\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curve fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = rand(20) * 6\n",
    "w = [.5; -2.; 1]\n",
    "y = [x.^2  x  ones(x)] * w  + rand(size(x)) * .2\n",
    "#         ^^^                      ^^^\n",
    "#   2nd degree polynomial       Noisy data\n",
    "\n",
    "plot(\n",
    "    layer(x=x, y=y, Geom.point),\n",
    "    layer(x -> dot([x^2; x; 1], w), 0, 6, Theme(default_color=colorant\"green\")),\n",
    "    Guide.title(\"Ground truth: w = $w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "esw = GradientDescent([1,1,1], rate=.001, N=5000) do w\n",
    "    mean(([x.^2  x  ones(x)] * w - y).^2)\n",
    "end\n",
    "\n",
    "plot(\n",
    "    layer(x=x, y=y, Geom.point),\n",
    "    layer(x -> dot([x^2; x; 1], w), 0, 6, Theme(default_color=colorant\"green\")),\n",
    "    layer(x -> dot([x^2; x; 1], esw), 0, 6, Theme(default_color=colorant\"red\")),\n",
    "    Guide.title(\"Estimate: w = $esw\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris = dataset(\"datasets\", \"iris\")\n",
    "plot(iris, x=:SepalWidth, y=:SepalLength, color=:Species) |> display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = convert(Array, iris[[:SepalWidth, :SepalLength, :PetalWidth]])\n",
    "y = convert(Array{Int64}, iris[:Species] .== \"setosa\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logit(x,w) = 1 / (1 + exp(-dot([x; 1], w)))\n",
    "\n",
    "logisticRegression(X,y) =\n",
    "    GradientDescent(rand(size(X,2)+1)) do w\n",
    "        e = 0 # Loss is negative log likelihood\n",
    "        for i = 1:size(X,1) # <<< A loop!\n",
    "            if y[i] == 0    # << Branches!\n",
    "                e += log(1-logit(X[i,:], w))\n",
    "            else\n",
    "                e += log(logit(X[i,:], w))\n",
    "            end\n",
    "        end\n",
    "        -e/size(X,1)\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = logisticRegression(X,y)\n",
    "show(w)\n",
    "pred = [logit(X[i,:], w) > .5 for i = 1:size(X,1)]\n",
    "plot(x=X[:,1], y=X[:,2], color=pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baggingLogisticRegression(X,y) =\n",
    "    GradientDescent(rand(size(X,2)+1)) do w\n",
    "        e = 0\n",
    "        for k = 1:size(X,1)*.6\n",
    "        \n",
    "            i = rand(1:size(X,1)) # <<< Random state!\n",
    "    \n",
    "            if y[i] == 0\n",
    "                e += log(1-logit(X[i,:], w))\n",
    "            else\n",
    "                e += log(logit(X[i,:], w))\n",
    "            end\n",
    "        end\n",
    "        -e/(size(X,1)*.6)\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = baggingLogisticRegression(X,y)\n",
    "show(w)\n",
    "pred = [logit(X[i,:], w) > .5 for i = 1:size(X,1)]\n",
    "plot(x=X[:,1], y=X[:,2], color=pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.1",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
